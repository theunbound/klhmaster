\chapter{Simulation studies}\label{ch.mc}

Now that the theoretical description of the processes under study is in place, we might suppose that obtaining a prediction of the distributions of events that an experiment will find is a simple matter of carrying out the integrals laid out in the previous chapter. Unfortunately, these integrals defy analytical solution, which leaves only the option of integrating numerically. Specifically, we will use the Monte Carlo method for numerical integration, which prescribes inserting a random value drawn from a suitable distribution into the integrand in place of the variable of integration, and then calculating the value of the integrand. Each result estimates the value of the integral, and by averaging several such estimates, an incrementally better estimate is obtained.

Since all of the variables that are integrated over have physical significance, choosing specific values for the variables of integration can be viewed as equivalent to laying out the kinematics of a single hypothetical event. Repeatedly estimating the value of the integral a sufficient number of times to obtain a result of acceptable accuracy from the Monte Carlo integration process in effect leaves us with a large set of such simulated events. In particle physics, this process goes by Monte Carlo simulation, and the software packages that are designed to carry out these calculations are called event generators.

\section{Event generators}

The event generator used for the bulk of the work in this thesis is CalcHEP \cite{calchep}.

Given a set of initial and final states and a list of Feynman rules, CalcHEP can construct all tree level diagrams that contribute to the specified process. By specifying a composite particle, such as a proton, CalcHEP will construct Feynman diagrams with initial states composed of any combination of particles that can be extracted from the given composite, weighted by a selected PDF. For generating our event samples, we specify protons with 4 TeV momentum in the initial state and two photons in the final state. Based on the collection of Feynman diagrams thus constructed, CalcHEP can then generate events according to those Feynman diagrams, in the correct proportions.

Other choices of event generators include MadGraph \cite{madgraph5} and pythia \cite{pythia}. To illustrate the behaviour of these different generators with respect to one another, figure~\ref{evgen} plots distributions of invariant mass ($M_{\gamma\gamma}$) and transverse momentum ($p_T$) of a set of simulated events generated by each one. To accurately compare the three, all are limited to tree level processes, to conform to the limitations of CalcHEP.

\begin{figure}[htp]
\begin{minipage}[b]{.69\textwidth}
\begin{infilsf} \tiny
\hspace{-1ex}\makebox[0pt][l]{\input{figures/genspt2}}
\end{infilsf}
\end{minipage}
\begin{minipage}[b]{.3\textwidth}
\subcaption{The distribution of $p_T^{\gamma_1}$, the transverse momentum of the leading photon, in the event samples produced by three event generators.}

\phantom{p}
\end{minipage}
\begin{minipage}[b]{.69\textwidth}
\begin{infilsf} \tiny
\hspace{-1ex}\makebox[0pt][l]{\input{figures/gensmgg}}
\end{infilsf}
\end{minipage}
\begin{minipage}[b]{.3\textwidth}
\subcaption{The distribution of $M_{\gamma\gamma},$ the invariant mass of the photon pair, in the event samples produced by three event generators.}

\phantom{p}
\end{minipage}
\caption{Plots showing the distributions of $p_T$ and $M_{\gamma\gamma}$ of events generated by the three event generators \cite{calchep,pythia,madgraph5}. Below, the ratio plots were created by dividing the content in each bin of the distributions with the content of the corresponding bin in the distribution for the CalcHEP sample. The errors on the bins were derived through standard error propagation. All these samples were produced using stratified sampling, where separate sets of events were produced for different ranges of $p_T$, as discussed in the text.
\label{evgen}}
\end{figure}

These plots, and those to follow in this chapter, have at some stage of their creation been through the analysis validation software \textsc{rivet}\footnote{\textbf{R}obust \textbf{I}ndependent \textbf{V}alidation of \textbf{E}xperiment and \textbf{T}heory.} \cite{rivet}.

The strong coupling constant, $\alpha_S$, is a so--called running coupling constant \cite{greenhpt}, meaning that its value changes depending on an energy scale, $Q$, at which it is examined. How this energy scale is determined is defined differently by default in CalcHEP than it is in pythia and MadGraph. To achieve the result in figure~\ref{evgen}, this setting in CalcHEP was changed to 
\[Q^2=\frac{p_T(\gamma_1)^2+p_T(\gamma_2)^2}{2},\]
which is the setting used in the other two event generators.

As figure~\ref{evgen} illustrates, there is a difference of 8--9 orders of magnitude between the number of events produced in the low and the high $p_T$ ranges. Covering this entire range requires more simulated events than we can feasibly analyse. To circumvent this issue, we employ stratified sampling, meaning that we create several smaller samples that cover successive ranges in a representative variable. In this case, we create four sets of events to cover the following ranges in $M_{\gamma\gamma}$:
\begin{enumerate}
\item $M_{\gamma\gamma} \in [ 0 ; 100 )$ GeV
\item $M_{\gamma\gamma} \in [ 100 ; 420 )$ GeV
\item $M_{\gamma\gamma} \in [ 420 ; 1000 )$ GeV
\item $M_{\gamma\gamma} \in [ 1000 ; \infty )$ GeV
\end{enumerate}
In fig~\ref{evgen}, one easily noticeable effect of this stratification of event samples is the jump in statistical uncertainties around 500 GeV in $p_T$ or 1\,000 GeV in $M_{\gamma\gamma}$.

In addition, the fiducial volume for the event sample is bounded by a minimum requirement of 50 GeV in $E_T$ and a maximum of 2.5 in $|\eta|$.

The event samples generated by CalcHEP and pythia are compatible with one another in both these distributions, however, the sample generated by MadGraph seems to produce fewer events with an invariant mass between 1\,000 and 2\,000 GeV compared to the other samples. This sample was not produced by the author, which makes investigation into the cause of this bias difficult. For the present analysis, the bias is included as a systematic uncertainty of 9.18\% on the overall normalisation arising from the choice of event generator, however it remains a possibility that this uncertainty could be reduced or eliminated by a more careful study.


\section{Discriminating variables}
To allow CalcHEP to generate events that involve the new contact interaction, we can simply extend the list of Feynman rules known to CalcHEP to include the new Feynman rule we found in chapter~\ref{ch.theory}, using LanHEP \cite{lanhep}. In practice, this involves giving as input a Lagrangian written in a format similar to \LaTeX's math language. LanHEP then produces a list of Feynman rules in a format appropriate for CalcHEP. This new model has two additional parameters: the size of $\Lambda$ and the sign of the interference of this new interaction with the existing processes.

With the ability to produce sets of events with varying values of $\Lambda$, the opportunity presents itself to create simulated distributions of events for several potential observables that we might examine to discriminate the effects of the contact interaction. To quantify the discriminating power of these observables, we define a figure of merit, which we will call `significance', as
\(S\equiv\ono{N}\sum_n \frac{|x_n-y_n|}{\sqrt{{\sigma_{x,n}}^2+{\sigma_{y,n}}^2}},\label{significance}\)
where the sum is over bins $n$ where both distributions have non--zero content, $N$ is the total number of bins where both distributions have non--zero content, $x_n$ and $y_n$ are the content of the two distributions in bin $n$, and $\sigma_{x,n}$ and $\sigma_{y,n}$ are the uncertainties on the bin content of each of the two distributions in bin $n$.
Results for a few selected variables are shown in figure~\ref{discr}.

\begin{figure}[htp]
\begin{minipage}[b]{.499\textwidth}
\begin{infilsf}\tiny
\hspace{-.9em}\makebox[.96\textwidth]{\input{figures/sigcosth}}
\end{infilsf}
\vspace{-1em}
\subcaption{Significance: 0.98 \label{sigcos}}
\end{minipage}
\hfill
\begin{minipage}[b]{.499\textwidth}
\begin{infilsf} \tiny
\makebox[.96\textwidth]{\input{figures/sigp}}
\end{infilsf}
\vspace{-1em}
\subcaption{Significance: 28.0}
\end{minipage}

\vspace{1em}

\noindent
\begin{minipage}[b]{.499\textwidth}
\begin{infilsf} \tiny
\hspace{-.2em}\makebox[.96\textwidth]{\input{figures/sigm} }
\end{infilsf}
\vspace{-1em}
\subcaption{Significance: 23.7}
\end{minipage}\hfill
\begin{minipage}[b]{.499\textwidth}
\begin{infilsf} \tiny
\makebox[.96\textwidth]{\input{figures/sigpp}}
\end{infilsf}
\vspace{-1em}
\subcaption{Significance: 23.6}
\end{minipage}
\begin{minipage}[t]{\textwidth}
\caption{The distributions of simulated events in four potential discriminating variables in event samples generated with Standard Model parameters, and with $\Lambda = 1.0$ TeV: (a) the cosine of $\theta_{\gamma_1}$, the scattering angle of the leading photon (measured, in this case, in the Collins-Soper frame \cite{collinssoper}), (b) $p_T^{\gamma_1}$, the transverse momentum of the leading (most energetic) photon, (c) $M_{\gamma\gamma}$, the invariant mass of the photon pair and (d) $|p_T|^{\gamma\gamma}$, the sum of magnitudes of $p_T$ of both photons. Both samples are generated with CalcHEP. The significance is calculated according to eq.~\eqref{significance}.
\label{discr}}
\end{minipage}
\end{figure}


Given the significances quoted in that figure, $p^{\gamma_1}_T$, the transverse momentum of the leading photon, is the obvious choice for a discriminating variable. It, along with the scattering angle, has the disadvantage when compared with the latter two methods, however, that it is dependant on identifying the leading---most energetic---photon of the pair. In a truth sample such as this, making such an identification does not present a problem, however when considering the effects on a photon of passing through the material of the detector, it becomes problematic to claim that the photon that leaves the largest energy deposit in the calorimeter is also the photon that left the hard event with the greatest amount of energy. The two remaining variables both incorporate information about both photons. The invariant mass additionally incorporates information about the relative orientation of the photons, which arguably makes it the most sophisticated measure. 


For this reason, we will use invariant mass as the discriminating variable going forward.

Meanwhile, figure~\ref{sigcos} shows no discernible difference between the SM sample and the sample generated with a 1 TeV mass scale contact interaction. Evidently, at the hard process level, the distribution of angles between photons is not affected by the new term.

\section{Parton Distribution Functions}
As described in section~\ref{sec.pdfth}, we use a set of experimentally determined functions called Parton Distribution Functions (PDFs) to describe the probability of extracting a given parton from a proton. Given that the PDFs are not exact analytical models, we must account for the uncertainty associated with the method by which  PDFs are determined. To estimate that uncertainty, we compare the distribution in invariant masses of events generated by CalcHEP using the CTEQ6 set of PDFs, which are the events that will be used moving forward, with events generated using the alternative MRST2002nlo set of PDF, which is the only alternative PDF available in CalcHEP.

\begin{figure}[htp]
\begin{minipage}[b]{.69\textwidth}
\begin{infilsf}\tiny
\input{figures/mrst}
\end{infilsf}
\end{minipage}
\begin{minipage}[b]{.3\textwidth}
\caption{Comparing the distribution of invariant masses of events produced by CalcHEP with the CTEQ6 (grayed) and MRST2002nlo (non--grayed) PDFs at different values of $\Lambda$, along with a ratio plot showing the differences between the distributions at each value of $\Lambda$. This is to give an idea of the systematic uncertainty on this distribution due to the choice of PDF. Table~\ref{mrsttab} summarises the fractional variation in predicted events by $\Lambda$ and invariant mass range. The invariant mass ranges used are discussed in the text. \label{mrst}}
\end{minipage}
\end{figure}
\begin{table}[htp]
\begin{minipage}[b]{\textwidth}
\begin{infilsf}{\footnotesize
\begin{center}
\arrayrulecolor{natgreen}
\begin{tabular}[b]{cr!{\color{white}|}r!{\color{white}|}r!{\color{white}|}r}\hline
&&\multicolumn{3}{c}{ \color{natgreen}{\bfseries $M_{\gamma\gamma}$ range [GeV]} } \\
&&\multicolumn{1}{c!{\color{white}\vrule}}{\bfseries [100:1000)} & \multicolumn{1}{c!{\color{white}\vrule}}{\bfseries [1000:3000)} & \multicolumn{1}{c}{\bfseries [3000:5000)} \\ %\cline{3-5}
& \textbf{0.75} & (13.1 ± 0.4) \% & (11.7 ± 0.5) \% & (31.9 ± 1.2) \% \\
&\textbf{1.00} & (12.4 ± 1.0) \% & (8.1 ± 0.5) \% & (32.1 ± 1.7) \% \\
\multirow{-3}{*}{\rotatebox[origin=c]{90}{\color{natgreen}{\bfseries $\Lambda$ [TeV]}}} &\textbf{$\infty$} & (12.0 ± 1.0) \% & (3.1 ± 0.6) \% & (56 ± 21) \%\\\hline
\end{tabular}
\end{center}}\end{infilsf}
\end{minipage}
\caption{The fractional deviation between the distribution of simulated events produced by CalcHEP with the CTEQ6 PDF versus the MSRT2002nlo PDF plotted in fig~\ref{mrst}. We use a $\Lambda$ value of $\infty$ as shorthand for the SM case, since inserting $\infty$ in $\Lambda$s place in eq.~\eqref{rizzo} causes the new term to equal zero. The errors are derived from the statistical errors in those distributions. This will form one of the systematic uncertainties on the final result. Note in regards to the lower right number that the presence of zero--value bins in this part of the distributions may skew the error too low. The lesson here is that while the two PDFs agree reasonably well on the Standard Model prediction, they produce significantly diverging results when the new interaction term is introduced. \label{mrsttab}}
\end{table}

The resulting distributions are plotted in fig~\ref{mrst}, and the difference between the sample generated using the CTEQ6 PDF set and the MRST2002 PDF set are quantified in table~\ref{mrsttab}, broken up into three invariant mass ranges: a low range with a great deal of statistics and very little separation between the three models, a middle range with good statistics and good separation between the models, and a high range where statistics start to run out, especially for the SM sample. Additionally, as we will return to in chapter~\ref{ch.data}, the data sample runs out of statistics below 2 TeV. Looking at the ratio plots in figure~\ref{mrst}, we must conclude that the predictions produced by the to PDFs differ in a non--trivial way, which depends on $\Lambda$. These deviations must be included in the analysis as a systematic uncertainty.

\begin{figure}[htb]
\includegraphics[width=\textwidth]{figures/Zep-soft}
\caption{An illustration of the processes that may surround an interesting event in a proton-proton collision, and the steps required to arrive at a final particle content of that event. In this figure, the dark gray blobs represent the incoming protons and the large red blob represents a hard quark-quark interaction. This figure reproduced from \cite{zep}. For further details on these surrounding processes and their computational representation, see e.g.~\cite{pythman}.
\label{zep}}
\end{figure}

\section{Parton level effects}
The events produced by the event generator(s) represent the hard physical process that occurs in the point where two protons interact. Given that we cannot observe such interactions at the moment they occur, and physics continues both before and after the hard event, we need to expand the scope of physical processes in the simulation, to the point where the resulting event information represents something that we might realistically observe with a detector.

Figure~\ref{zep} gives a schematic overview of the processes that might occur in a proton interaction in addition to the hard process---the red blob---along with a list of steps that a simulation of these processes typically goes through.

Initial and final state radiation are of particular importance in the present analysis, since these can directly produce photons, which might enter into our signal reconstruction.

Figure~\ref{zep} also illustrates how we might see more than one interaction between the constituents of interacting protons. In this case, several additional gluons are emitted.

Final state particles with colour charge, such as gluons, will not remain isolated due to colour confinement. These particles will develop a jet of other coloured particles about themselves, so that the colour charge is neutralised to outside observation. The simulation of the process by which colour charged particles combine into colour neutral hadrons is simulated is called hadronisation. This simulates how a single coloured particle evolves into several colour--neutral hadrons in the space between the interaction point and the detectors. Due to the kinematics involved, the hadrons produced by a single particle will remain close enough together that the detector can not distinguish the individual particles from one another. We refer to such an object as a jet. Since we are dealing with photons in the final state in the present analysis, this step is not crucial in the events generated to study this process specifically, however $\pi^0$ mesons, one of the major backgrounds to the photon signal, are produced in this way. 

In this thesis, the extension of the hard events provided by CalcHEP with these surrounding processes will be carried out in pythia8 \cite{pythia}. Figure~\ref{pythify} illustrates the effect that these surrounding processes have on the distribution of invariant masses.

\begin{figure}[htp]
\centering
\begin{minipage}[b]{.69\textwidth}\hspace{-1.5em}\makebox[0pt][l]{
\noindent\begin{infilsf}
\tiny
\input{figures/bfpyth}
\end{infilsf}}
\end{minipage}\hfill
%\begin{minipage}[b]{.\textwidth}
\caption{The distribution of invariant masses in the event samples generated by CalcHEP at three values of $\Lambda$, and the same event samples after extending them in surrounding processes with pythia, with ratio plots. Once again, the effect of the use of stratified sampling is visible as a jump in the magnitude of the errors around 1000 GeV.
\label{pythify}}
%\end{minipage}
\end{figure}

Here, the ratio plots make it clear that the effect upon this particular observable of overlaying parton level effects is simply to remove a fraction of the events. This is reasonable, since the effect of adding final state radiation to a hard event is to alter the final state particle content for a fraction of those events, and since we require two final state photons to calculate an invariant mass, final states that do not contain two photons are discarded in the \textsc{rivet} analysis step. We can conclude from this figure that the selection of events with altered final state particle content does not depend on the invariant mass of the photons in the event, nor does the process of overlaying parton level effects alter the distribution of photon invariant masses.

This constant difference in distributions between the process level and parton level event samples does not apply for all observables. Figure~\ref{pythicos} illustrates how the distribution of cos $\theta_{\gamma_1}$, the scattering angle for the leading photon is skewed slightly toward lower values, meaning a greater proportion of large scattering angles. This could be an effect of extended events having their kinematics altered so that the leading photon in the extended event is not the same as the leading photon in the hard event, so that the subleading photon, which scatter in the opposite direction from the leading photon, spill into the leading photon sample. This would also explain why the shape of the invariant mass distribution, which is not sensitive to the identification of a leading photon, is not affected.

\begin{figure}[htp]
\begin{minipage}[b]{.65\textwidth}
\begin{infilsf} \tiny \makebox[0pt][l]{
\hspace{-1em}\input{figures/pythicos}
}\end{infilsf}
\end{minipage}
\hfill\begin{minipage}[b]{.3\textwidth}
\caption{A plot of the distribution of the cosine of the scattering angle $\theta$ (in the CS frame, as in fig.~\ref{discr}) of the leading photon in the set of events generated by CalcHEP in the SM scenario before (green) and after (red) being extended with pythia. Aside from the same constant faction of lost events as was also seen in fig.~\ref{pythify}, we note that the distribution contains events with lower $\cos\theta_{\gamma_1}$ than were present in the set of generated events.
\label{pythicos}}
\end{minipage}
\end{figure}

Since the main process under study does not involve coloured final states, we do not expect that these surrounding processes will be a significant source of systematic uncertainty or bias, We are supported in this assumption by the findings in figure~\ref{pythify}. To support that expectation beyond what is done here, one might attempt to add the extended processes with a different software package.

