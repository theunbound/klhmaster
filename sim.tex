\chapter{Simulation studies}\label{ch.mc}

Now that the theoretical description of the processes under study is in place, we might suppose that obtaining a prediction of the distributions of events that an experiment will find is a simple matter of carrying out the integrals laid out in the previous chapter. Unfortunately, these integrals defy analytical solution, which leaves only the option of integrating numerically. Specifically, we will use the Monte Carlo method for numerical integration, which prescribes inserting a random value drawn from a suitable distribution into the integrand in place of the variable of integration, and then calculating the value of the integrand. Each result estimates the value of the integral, and by averaging several such estimates, an incrementally better estimate is obtained.

Since all of the variables that are integrated over have physical significance, choosing specific values for the variables of integration can be viewed as equivalent to laying out the kinematics of a single hypothetical event. Repeatedly estimating the value of the integral a sufficient number of times to obtain a result of acceptable accuracy from the Monte Carlo integration process in effect leaves us with a large set of such simulated events. In particle physics, this process goes by Monte Carlo simulation, and the software packages that are designed to carry out these calculations are called event generators.

\section{Event generators}

The event generator used for the bulk of the work in this thesis is CalcHEP \cite{calchep}. Other choices of event generators include MadGraph \cite{madgraph5} and pythia \cite{pythia}. To illustrate the behaviour of these different generators with respect to one another, figure~\ref{evgen} plots distributions of invariant mass ($M_{\gamma\gamma}$) and transverse momentum ($p_T$) of a set of simulated events generated by each one.

\begin{figure}[htp]
\begin{minipage}[b]{.69\textwidth}
\begin{infilsf} \tiny
\hspace{-1ex}\makebox[0pt][l]{\input{figures/genspt2}}
\end{infilsf}
\end{minipage}
\begin{minipage}[b]{.3\textwidth}
\subcaption{The distribution of $p_T^{\gamma_1}$, the transverse momentum of the leading photon, in the event samples produced by three event generators. There is a general trend toward pythia producing more events and MadGraph producing fewer events than CalcHEP, however these distributions are still compatible with one another within their errors.}

\phantom{p}
\end{minipage}
\begin{minipage}[b]{.69\textwidth}
\begin{infilsf} \tiny
\hspace{-1ex}\makebox[0pt][l]{\input{figures/gensmgg}}
\end{infilsf}
\end{minipage}
\begin{minipage}[b]{.3\textwidth}
\subcaption{The distribution of $M_{\gamma\gamma},$ the invariant mass of the photon pair, in the event samples produced by three event generoatrs. pythia's tendency to produce more events is less pronounced in this distribution, however MadGraph's trend toward fewer events is more pronounced, especially in the region with high statistics between 1000 and 1500 GeV, where the number of events produced by MadGraph and CalcHEP differ by as much as 4 standard deviations over several bins.}

\phantom{p}
\end{minipage}
\caption{Plots showing the distributions of $p_T$ and $M_{\gamma\gamma}$ of events generated by the three event generators \cite{calchep} \cite{pythia} \cite{madgraph5}. Below, the ratio plots were created by dividing the content in each bin of the distributions with the content of the corresponding bin in the distribution for the CalcHEP sample. The errors on the bins were derived through standard error propagation. All these samples were produced using stratified sampling, where seperate sets of events were produced for different ranges of $p_T$, which is why the error bars fluctuate in size somewhat. The MadGraph sample shows a clear bias, which indicates a systematic uncertainty. Note though, that the MadGraph samples were not produced by the author, who cannot verify that the production setting match those used in the other event generators. Nevertheless, a systematic uncertainty of [something] due to the event generator selection will be included.
\label{evgen}}
\end{figure}

These plots, and those to follow in this chapter, have at some stage of their creation been through the analysis validation software \textsc{rivet}\footnote{\textbf{R}obust \textbf{I}ndependent \textbf{V}alidation of \textbf{E}xperiment and \textbf{T}heory.} \cite{rivet}.

By default, the energy scale $Q^2$, on which the running of the strong coupling constant, $\alpha_S$, depends, is defined differently in CalcHEP than it is in pythia and MadGraph. To achieve the result in figure~\ref{evgen}, this default was changed to 
\[Q^2=\frac{p_T(\gamma_1)^2+p_T(\gamma_2)^2}{2},\]
which matches the setting in the other two event generators.

As figure~\ref{evgen} illustrates, the event sample generated by MadGraph show a significant bias compared to the other samples. This sample was not produced by the author, which makes investigation into the cause of this bias difficult. For the present analysis, the bias is included as a systematic uncertainty, however it remains a possibility that this uncertainty could be reduced or eliminated by a more careful study.


\section{Feynman rule calculators}
The event generators introduced above assemble events based on sets of Feynman rules (in a computerised format), so to generate events from a model that includes the new contact interaction, the new term in the Lagrangian that describes the contact interaction must be expressed as a set of Feynman rules (in the correct computerised format). As was hinted at when the Feynman diagrams that describe the new interaction were introduced in figure~\ref{rule}, there exist automated ways of carrying out this conversion. For this thesis, the tool used was LanHEP \cite{lanhep}, which was designed as a companion to CalcHEP's antecedant CompHEP, and as such, it and CalcHEP interface readily. Alternatives exist, however, such as the Mathematica package FeynRules~\cite{feynrules}. 

LanHEP takes as input a Lagrangian written in a format similar to \LaTeX's math language, and produces a set of Feynman rules usable by CalcHEP.

With the ability to produce sets of events with varying values of $\Lambda$, the mass scale of the contact interaction, the opportunity presents itself to create simulated distributions of events for several potential observables with which we might discriminate the effects of the contact interaction. To quantify the discriminating power of these observables, we define a figure of merit, which we will call `significance', as
\[S\equiv\sum_n \frac{|x_n-y_n|}{\sqrt{{\sigma_{x,n}}^2+{\sigma_{y,n}}^2}},\]
where $x_n$ and $y_n$ are the content of the two distributions in bin $n$, and $\sigma_{x,n}$ and $\sigma_{y,n}$ are the uncertainties on the bin content of each of the two distributions in bin $n$, and the sum is over all bins.
Results for a few selected variables are shown in figure~\ref{discr}.

\begin{figure}[htp]
\begin{minipage}[b]{.499\textwidth}
\begin{infilsf}\tiny
\hspace{-.9em}\makebox[.96\textwidth]{\input{figures/sigcosth}}
\end{infilsf}
\vspace{-1em}
\subcaption{Significance: 30.4 \label{sigcos}}
\end{minipage}
\hfill
\begin{minipage}[b]{.499\textwidth}
\begin{infilsf} \tiny
\makebox[.96\textwidth]{\input{figures/sigp}}
\end{infilsf}
\vspace{-1em}
\subcaption{Significance: 671.5}
\end{minipage}

\vspace{1em}

\noindent
\begin{minipage}[b]{.499\textwidth}
\begin{infilsf} \tiny
\hspace{-.2em}\makebox[.96\textwidth]{\input{figures/sigm} }
\end{infilsf}
\vspace{-1em}
\subcaption{Significance: 963.2}
\end{minipage}\hfill
\begin{minipage}[b]{.499\textwidth}
\begin{infilsf} \tiny
\makebox[.96\textwidth]{\input{figures/sigpp}}
\end{infilsf}
\vspace{-1em}
\subcaption{Significance: 848.5}
\end{minipage}
\begin{minipage}[t]{\textwidth}
\caption{The distributions of simulated events in four potential discriminating variables in event samples generated with Standard Model parameters, and with $\Lambda = 1.0$ TeV: (a) the cosine of $\theta_{\gamma_1}$, the scattering angle of the leading photon (measured, in this case, in the Collins-Soper frame \cite{collinssoper}), (b) $p_T^{\gamma_1}$, the transverse momentum of the leading (most energetic) photon, (c) $M_{\gamma\gamma}$, the invariant mass of the photon pair and (d) $|p_T|^{\gamma\gamma}$, the sum of magnitudes of $p_T$ of both photons. Both samples are generated with CalcHEP. The significance is calculated as the difference in bin content between the two distributions divided by the root--sum--square of the errors on the bins, summed over all bins where both distributions have non--zero content.
\label{discr}}
\end{minipage}
\end{figure}


Given the significances quoted in that figure, $M_{\gamma\gamma}$, the invariant mass, is the obvious choice for a discriminating variable. It has the additional advantage over the first two methods that it does not depend on identifying the leading---most energetic---photon of the pair. In a truth sample such as this, making such an identification does not present a problem, however when considering the effects on a photon of passing through the material of the detector, it becomes problematic to claim that the photon that leaves the largest energy deposit in the calorimeter is also the photon that left the hard event with the greatest amount of energy. The two remaining variables both incorporate information about both photons. The invariant mass additionally incorporates information about the relative orientation of the photons, which arguably makes it the most sophisticated measure. It also has slightly better significance than the sum of absolute transverse momenta.

One argument against the measure of significance used here is that it rewards observables where both distributions have many non-zero bins, which is the result of a choice made about how the data is represented, rather than something intrinsic to the data. However, since the per-bin differences are weighted by the error on each bin, we expect that a distribution with a single bin with a very significant difference between bin contents is scored similarly to a distribution with a large number of bins with relatively insignificant differences between bin contents. This speaks in this method's favour, since we could create a distribution like the first one by combining the bins of the latter distribution, assuming the differences between the distributions are in the same direction for all the bins.

Backed by these considerations, we will use invariant mass as the discriminating variable going forward.

Meanwhile, figure~\ref{sigcos} shows no discernible difference between the SM sample and the sample generated with a 1 TeV mass scale contact interaction. \sout{Samples generated at lower mass scales do show a significant difference, although it changes only the scale, and not the shape, of the distribution. [Possibly a plot will happen at some point.]} Evidently, at the hard process level, the distribution of angles between photons is not affected by the new term.

\section{Parton Distribution Functions}
As described in section~\ref{sec.pdfth}, we use a set of experimentally determined functions called Parton Distribution Functions (PDFs) to describe the probability of extracting a given parton from a proton. Given that the PDFs are not exact analytical models, we must account for the uncertainty associated with the method by which  PDFs are determined. To estimate that uncertainty, we compare the distribution in invariant masses of events generated by CalcHEP using the CTEQ6 set of PDFs, which are the events that will be used moving forward, with events generated using the alternative MRST2002nlo set of PDF, which is the only alternative PDF available in CalcHEP.

\begin{figure}[htp]
\begin{minipage}[b]{.69\textwidth}
\begin{infilsf}
\hspace{-.8cm}\input{figures/mrst}
\end{infilsf}
\end{minipage}
\begin{minipage}[b]{.3\textwidth}
\caption{Comparing the distribution of invariant masses of events produced by CalcHEP with the CTEQ6 (grayed) and MRST2002nlo (non-grayed) PDFs at different values of $\Lambda$. This is to give an idea of the systematic uncertainty on this distribution due to the choice of PDF. Table~\ref{mrsttab} summarizes the fractional variation in predicted events by $\Lambda$ and invariant mass range. The invariant mass ranges used, indicated by the dashed lines in this plot, are discussed in the text. \label{mrst}}
\end{minipage}
\end{figure}
\begin{table}[htp]
\begin{minipage}[b]{.69\textwidth}
\begin{infilsf}{\footnotesize
\begin{center}
\arrayrulecolor{natgreen}
\begin{tabular}[b]{cr!{\color{white}|}r!{\color{white}|}r!{\color{white}|}r}\hline
&&\multicolumn{3}{c}{ \color{natgreen}{\bfseries $M_{\gamma\gamma}$ range [GeV]} } \\
&&\multicolumn{1}{c!{\color{white}\vrule}}{\bfseries [100:1000)} & \multicolumn{1}{c!{\color{white}\vrule}}{\bfseries [1000:3000)} & \multicolumn{1}{c}{\bfseries [3000:5000)} \\ %\cline{3-5}
& \textbf{0.75} & 16.9 \% & 11.1 \% & 31.9 \% \\
&\textbf{1.00} & 16.3 \% & 7.7 \% & 32.2 \% \\
\multirow{-3}{*}{\rotatebox[origin=c]{90}{\color{natgreen}{\bfseries $\Lambda$ [TeV]}}} &\textbf{$\infty$} & 16.8 \% & 3.4 \% & 51.1 \%\\\hline
\end{tabular}
\end{center}}\end{infilsf}
\end{minipage}
\begin{minipage}[b]{.3\textwidth}
\caption{The fractional deviation between the distribution of simulated events produced by CalcHEP with the CTEQ6 PDF versus the MSRT2002nlo PDF plotted in fig~\ref{mrst}. This will form one of the systematic uncertainties on the final result. \label{mrsttab}}
\end{minipage}
\end{table}

The resulting distributions are plotted in fig~\ref{mrst}, and the difference between the sample generated using the CTEQ6 PDF set and the MRST2002 PDF set are quantified in table~\ref{mrsttab}, broken up into three invariant mass ranges: a low range with a great deal of statistics and very little separation between the three models, a middle range with good statistics and good separation between the models, and a high range where statistics start to run out, especially for the SM sample. These deviations will be included in the analysis as a systematic uncertainty.

\begin{figure}[htb]
\includegraphics[width=\textwidth]{figures/Zep-soft}
\caption{An illustration of the processes that may surround an interesting event in a proton-proton collision, and the steps required to arrive at a final particle content of that event. In this figure, the dark gray blobs represent the incoming protons and the large red blob represents a hard quark-quark interaction. As illustrated here, the products of such a hard interaction may carry colour charge as well, in which case these products too would need to undergo hadronisation, which, in turn, would show up in the detector as jets. However, since the end product of the process currently under study is photons, which are colourless, that will not be the case here. The upper portion of the figure illustrates the evolution of a secondary gluon interaction, which, though a number of gluon emissions, produces a selection of quark final states that must be gathered into colourless clusters and finally into hadrons. Both stages may undergo further evolution or decay during the process. The final collection of hadrons, which for a single parton interaction will be reasonably well collimated, form a jet of particles in the detector. Similar jet-forming processes may also attach to particles emitted as initial or final state radiation. This figure reproduced from \cite{zep}. For further details on these surrounding processes and their computational representation, see e.g.~\cite{pythman}.
\label{zep}}
\end{figure}

\section{Extended event}
The events produced by the event generator(s) represent the physical process that occurs in the point where two protons interact. Given the limits on our ability to see such interactions, we need to exptend the scope of physical processes in the simulation, to the point where the resulting event information represents something that we might realistically observe with a detector.

The initial and final particle states are fixed in the event generator, however in reality, both initial and final states might easily undergo decay or emission before or after the event occurs, altering the particle content and kinematics of the event. Such initial and final state radiation must be modelled to give an accurate picture of what a detector might see.

Further, final state particles with colour charge will not remain isolated due to colour confinement. These particles will develop a jet of other coloured particles, so that the colour charge becomes obscured to outside observation. The simulation of the process by which colour charged particles combine into colour neutral hadrons is simulated is called hadronisation. Since we are dealing with photons in the final state in the present analysis, this step is not crucial in the events generated to study this process specifically, however $\pi^0$ mesons, one of the major backgrounds to the photon signal, are produced in this way. 

A schematic summary of these processes, along with the steps that the simulation software that models these processes will usually be divided into, is presented in figure~\ref{zep}. In this thesis, the extension of the hard events provided by CalcHEP with these surrounding processes will be carried out in pythia8 \cite{pythia}. Figure~\ref{pythify} illustrates the effect that these surrounding processes have on the distribution of invariant masses.

\begin{figure}[htp]
\centering
\begin{minipage}[b]{.69\textwidth}\hspace{-1.5em}\makebox[0pt][l]{
\noindent\begin{infilsf}
\tiny
\input{figures/bfpyth}
\end{infilsf}}
\end{minipage}\hfill
%\begin{minipage}[b]{.\textwidth}
\caption{The distribution of invariant masses in the event samples generated by CalcHEP at three values of $\Lambda$, and the same event samples after extending them in surrounding processes with pythia, with ratio plots. Once again, the effect of the use of stratified sampling is visible as a jump in the magnitude of the errors around 1000 GeV. The ratio plots make it clear that the effect on this particular observable of creating the extended events is simply to remove a fraction of the events. This is reasonable, since the effect of adding final state radiation to a hard event is to alter the final state particle content for a fraction of those events, and since we require two final state photons to calculate an invariant mass, final states that do not contain two photons are discarded. We can conclude from this figure that the selection of events with altered final state particle content does not depend on the invariant mass of the photons in the event, nor does the process of extending the event alter the distribution of photon invariant masses.
\label{pythify}}
%\end{minipage}
\end{figure}

This constant difference in distributions between the hard and extended event samples does not apply for all observables. Figure~\ref{pythicos} illustrates how the distribution of cos $\theta_{\gamma_1}$, the scattering angle for the leading photon is skewed slightly toward lower values, meaning a greater proportion of large scattering angles. This could be an effect of extended events having their kinematics altered so that the leading photon in the extended event is not the same as the leading photon in the hard event, so that the subleading photon, which scatter in the opposite direction from the leading photon, spill into the leading photon sample. This would also explain why the invariant mass sample, which is not sensitive to the identification of a leading photon, is not affected.

\begin{figure}[htp]
\begin{minipage}[b]{.65\textwidth}
\begin{infilsf} \tiny \makebox[0pt][l]{
\hspace{-1em}\input{figures/pythicos}
}\end{infilsf}
\end{minipage}
\hfill\begin{minipage}[b]{.3\textwidth}
\caption{A plot of the distribution of the cosine of the scattering angle $\theta$ (in the CS frame, as in fig.~\ref{discr}) of the leading photon in the set of events generated by CalcHEP in the SM scenario before (green) and after (red) being extended with pythia. Aside from the same constant faction of lost events as was also seen in fig.~\ref{pythify}, we note that the distribution contains events with lower $\cos\theta_{\gamma_1}$ than were present in the set of generated events.
\label{pythicos}}
\end{minipage}
\end{figure}

Since the main process under study does not involve coloured final states, we do not expect that these surrounding processes will be a significant source of systematic uncertainty or bias, We are supported in this assumption by the findings in figure~\ref{pythify}. To further support that expectation we might attempt to add the extended processes with a different software package, however [that would require us to spend time figuring out how such a thing works...]

\section{Detector simulation}
At this point, we have a precise picture of every detail of a number of hypothetical events. In that way, it is very unlike the picture that the detector will give us of the events that actually happen in the experiment.

The actual events will be viewed through the `lens' of the ATLAS detector, which only sees the particles passing through it as energy deposits in various detector elements, and the computer algorithms used to reconstruct the particles that caused those deposits\footnote{This description of the ATLAS detector will be expanded upon in chapter~\ref{ch.exp}.}. Additionally, the particles found as the end product of the interactions by pythia can potentially interact with the material that makes up the detector, and decay, split or convert before or during their detection, and the detector may not fully or accurately detect all the particles that pass through it.

Because of this, it is necessary to also simulate how the detector interacts with the final state particles we generated in the previous section, to properly relate that information with experimental data. Additionally, since the same software that reconstructs particle information from detector data is used to reconstruct simulated particle information from simulated detector data, the end product of the simulated events will be in the same format, containing the same variables, as the data available from the experiment.

Once this final step is completed, we will have a set of hypothetical events as we imagine they would look if they were to happen in the experiment---a set of pseudo-experiments.

Since creating such pseudo-experiments is necessary for a large portion of analyses that wish to make use of \atlas{} data, the \atlas{} collaboration has created a digital description of the physical structure of the \atlas{} detector. The interaction between particles emanating from the interaction and the detector is then simulated by the \textsc{geant}4~\cite{geant4} software.

The real detector has a finite energy resolution, which is not reflected in the Monte Carlo events, for which we have an exact momentum. To overcome this, we smear the energies given by the simulation---that is shift the energies by a random amount chosen from a gaussian distribution with a width chosen to reflect the resolution of the detector.

The effect that the detector simulation has on the invariant mass distribution of the event samples created above is shown in figure~\ref{geant-beaf}.

\begin{figure}[htp]
\begin{minipage}[b]{.69\textwidth}
\begin{infilsf} \tiny
\input{figures/geant-beaf}
\end{infilsf}
\end{minipage}
\hfill\begin{minipage}[b]{.3\textwidth}
\caption{A plot comparing the event samples produced by CalcHEP and pythia with the results of running those event through the detector simulation available through GEANT4. We note a clear trend toward fewer reconstructed photon pairs at higher invariant masses. \label{geant-beaf}}
\end{minipage}
\end{figure}

Alternatively, we might extrapolate a systematic description of how the detector affects distributions of events from performing this simulation on several event sets, and apply that description to any new distribution of events as a simple correction[, and if we were going to compare the two methods, this would be the place for it...]

\section{Pileup}

[Which is a thing. More information is forthcoming. Probably.

Or maybe it isn't a thing. Who knows? Excitement!

It's definitely a thing. A lot of time went into that sentence.]